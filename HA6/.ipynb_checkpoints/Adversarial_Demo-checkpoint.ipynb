{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vag2WYR6yTOC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGCdmDAKpLuf"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiTHY8dqxzx7"
   },
   "source": [
    "Let's pick and load a pretrained model! \n",
    "Or build your own, save as .h5 file, load!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqhk2vYx6Ag0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "14540800/14536120 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "\n",
    "# pretrained_model = tf.keras.applications.resnet50.ResNet50(include_top=True,\n",
    "#                                                      weights='imagenet')\n",
    "\n",
    "# pretrained_model = tf.keras.applications.inception_v3.InceptionV3(include_top=True,\n",
    "#                                                                   weights='imagenet')\n",
    "\n",
    "# pretrained_model = tf.keras.applications.nasnet.NASNetMobile(include_top=True,\n",
    "#                                                              weights='imagenet')\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "# ImageNet labels #Decoder is the same for all pretrained imagenet models.\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2cLrJH0zpfC"
   },
   "outputs": [],
   "source": [
    "# Helper function to preprocess the image so that it can be inputted in MobileNetV2\n",
    "def preprocess(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255\n",
    "    image = image / tf.math.reduce_max(image)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image[None, ...]\n",
    "    return image\n",
    "\n",
    "# Helper function to extract labels from probability vector\n",
    "def get_imagenet_label(probs):\n",
    "    return decode_predictions(probs, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpYrQ4OQSYWk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 14:53:04.747224: W tensorflow/core/framework/op_kernel.cc:1775] OP_REQUIRES failed at whole_file_read_ops.cc:116 : Not found: /content/ad.jpg; No such file or directory\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/content/ad.jpg; No such file or directory [Op:ReadFile]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8j/gcjktp6s2wn3l5pd66pyr67w0000gn/T/ipykernel_78099/4038105450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Upload any image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/ad.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       return read_file_eager_fallback(\n\u001b[0m\u001b[1;32m    559\u001b[0m           filename, name=name, ctx=_ctx)\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[0m\u001b[1;32m    597\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /content/ad.jpg; No such file or directory [Op:ReadFile]"
     ]
    }
   ],
   "source": [
    "#Upload any image\n",
    "image_raw = tf.io.read_file(\"images/1.png\") \n",
    "image = tf.image.decode_image(image_raw,3)\n",
    "\n",
    "image = preprocess(image)\n",
    "image_probs = pretrained_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zdzqs2kZh0ih"
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvPlta_uSbuI"
   },
   "source": [
    "Let's have a look at the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99Jc-SNoSZot"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image[0])\n",
    "_, image_class, class_confidence = get_imagenet_label(image_probs)\n",
    "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kElVTbF690CF"
   },
   "source": [
    "## Create the adversarial image\n",
    "\n",
    "### Implementing fast gradient sign method\n",
    "The first step is to create perturbations which will be used to distort the original image resulting in an adversarial image. As mentioned, for this task, the gradients are taken with respect to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhZxlOnuBCVr"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image) \n",
    "        prediction = pretrained_model(input_image)\n",
    "        loss = loss_object(input_label, prediction)\n",
    "\n",
    "    # Get the gradients of the loss w.r.t to the input image.\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    # Get the sign of the gradients to create the perturbation\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad, gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbuftX0eSlDQ"
   },
   "source": [
    "The resulting perturbations can also be visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVjnb6M7Smv4"
   },
   "outputs": [],
   "source": [
    "# Get the input label of the image.\n",
    "labrador_retriever_index = 208\n",
    "label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
    "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
    "\n",
    "perturbations , enhance = create_adversarial_pattern(image, label)\n",
    "plt.imshow(perturbations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5h43KY9i2ZQ"
   },
   "outputs": [],
   "source": [
    "perturbations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKKSFHjwCyQH"
   },
   "source": [
    "Let's try this out for different values of epsilon and observe the resultant image. You'll notice that as the value of epsilon is increased, it becomes easier to fool the network. However, this comes as a trade-off which results in the perturbations becoming more identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBtG0Kl5SspV"
   },
   "outputs": [],
   "source": [
    "def display_images(image, description):\n",
    "  \n",
    "    _, label, confidence = get_imagenet_label(pretrained_model.predict(image))\n",
    "    plt.figure()\n",
    "    plt.imshow(image[0])\n",
    "    plt.title('{} \\n {} : {:.2f}% Confidence'.format(description,\n",
    "                                                   label, confidence*100))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Wb6EF-1lUow"
   },
   "outputs": [],
   "source": [
    "epsilons = [0, 0.001, 0.5]\n",
    "descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n",
    "                for eps in epsilons]\n",
    "\n",
    "for i, eps in enumerate(epsilons):\n",
    "    adv_x = eps*perturbations + image \n",
    "    adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "    display_images(adv_x, descriptions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gm11rklSyx5Q"
   },
   "source": [
    "We can look at different intensity of perturbation and what model sees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DA8g-Zp69J4"
   },
   "outputs": [],
   "source": [
    "epsilons = [0, 0.2, 1]\n",
    "descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n",
    "                for eps in epsilons]\n",
    "\n",
    "for i, eps in enumerate(epsilons):\n",
    "    adv_x = eps*perturbations# + image \n",
    "    adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "    display_images(adv_x, descriptions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKrLp-QYy9Bh"
   },
   "source": [
    "We can also add different noise level to \"enhance\" the confidence of model.\n",
    "However, adding too much will hurt more than help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TLbuGDROzL40"
   },
   "source": [
    "Note that now the noise added is **negative of gradient**.\n",
    "This is what we usually do for gradient descend\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPKOxkkG49--"
   },
   "source": [
    "Iterative attack:\n",
    "First, pick a class index.\n",
    "Then start the attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ISi8B3ue3gq"
   },
   "outputs": [],
   "source": [
    "image_raw = tf.io.read_file(\"/content/ad.jpg\")\n",
    "image = tf.image.decode_image(image_raw,3)\n",
    "\n",
    "image = preprocess(image)\n",
    "\n",
    "index = 208 #Find class index here: https://github.com/USCDataScience/dl4j-kerasimport-examples/blob/master/dl4j-import-example/data/imagenet_class_index.json\n",
    "label = tf.one_hot(index, image_probs.shape[-1])\n",
    "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
    "perturbations , enhance = create_adversarial_pattern(image, label)\n",
    "accumulated = 0*image #accumulate gradients over the iterations\n",
    "for j in range(20): #Most attacks will start to show result before 100 iterations\n",
    "\n",
    "    epsilons = [-0.01]\n",
    "    descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n",
    "                  for eps in epsilons]\n",
    "\n",
    "    for i, eps in enumerate(epsilons):\n",
    "    accumulated = eps*enhance + accumulated\n",
    "    adv_x = eps*enhance + image \n",
    "    adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "    display_images(adv_x, j)\n",
    "    perturbations , enhance = create_adversarial_pattern(image, label)\n",
    "    image = adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-m2cjp8KcaR_"
   },
   "outputs": [],
   "source": [
    "display_images(accumulated, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSWuNJ5xsphR"
   },
   "outputs": [],
   "source": [
    "display_images(accumulated*50, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLHO3iEigonc"
   },
   "outputs": [],
   "source": [
    "image_raw = tf.io.read_file(\"/content/cat.jpeg\")\n",
    "image = tf.image.decode_image(image_raw,3)\n",
    "\n",
    "image = preprocess(image)\n",
    "display_images(accumulated*1+image, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia_U08zNkGAY"
   },
   "source": [
    "This approach is not an Universial attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVp3yegpOgwk"
   },
   "source": [
    "Some fast exercises:\n",
    "\n",
    "1. Try create Universial attack  \n",
    "2. Test transferability of attack on different models. \n",
    "3. Plot and analyze accuracy lost among different models per iteration\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Adversarial Demo.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
